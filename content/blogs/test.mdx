---
title: "How I Built a Scalable Multi-Environment Infrastructure on GCP Using Terraform"
summary: "A complete guide to building scalable, isolated, multi-environment infrastructure on Google Cloud using Terraform and Cloud Build â€” by RizeForge."
tags: ["terraform", "gcp", "devops", "cloud", "infrastructure"]
banner: "/images/mastering-multi-environment-infrastructure-gcp-terraform.png"
publishedAt: "2025-06-29"
---

Hi, Iâ€™m **RizeForge**, a software engineer passionate about **DevOps automation and cloud infrastructure design**.

This project reflects my experience architecting **multi-environment Terraform infrastructure on Google Cloud**, ensuring every deployment â€” from development to production â€” remains consistent, secure, and scalable.

This post documents how I approached the problem, designed a modular setup, automated CI/CD with Cloud Build, and applied best practices for long-term maintainability.

---

## ğŸ§  Overview

Managing multiple environments in cloud infrastructure is one of the hardest DevOps challenges.  
This case study explains how I built a **production-ready, multi-environment Terraform setup on GCP** â€” clean, modular, secure, and CI/CD-driven.  

The result: isolated environments, reusable modules, automated pipelines, and bulletproof state management â€” a foundation that has scaled across multiple internal projects.

---

## ğŸ§© Tech Stack

```bash filename="stack.txt"
Cloud Provider: Google Cloud Platform (GCP)
IaC Tool: Terraform (v1.5+)
CI/CD: Google Cloud Build
Scripting: Bash
State Management: GCS Buckets (per environment)
Monitoring: Cloud Monitoring + Alerting
````

---

## âš™ï¸ Architecture & Project Structure

To ensure scalability, I used a **modular directory structure** that separates reusable infrastructure logic from environment-specific configuration:

```text
my-gcp-infrastructure/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ compute/
â”‚   â”œâ”€â”€ networking/
â”‚   â”œâ”€â”€ storage/
â”‚   â””â”€â”€ monitoring/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”œâ”€â”€ staging/
â”‚   â””â”€â”€ prod/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â”œâ”€â”€ destroy.sh
â”‚   â””â”€â”€ validate.sh
â””â”€â”€ cloudbuild/
    â”œâ”€â”€ cloudbuild-dev.yaml
    â”œâ”€â”€ cloudbuild-staging.yaml
    â””â”€â”€ cloudbuild-prod.yaml
```

**Why this matters:**

* âœ… Clear separation of reusable modules and configurations.
* ğŸ”’ Environment isolation through separate backend states.
* âš™ï¸ CI/CD flexibility with environment-specific pipelines.

---

## ğŸ§± Environment Configuration

Each environment (Dev, Staging, Prod) includes dedicated variable, backend, and tfvars files.

```hcl filename="environments/dev/variables.tf"
variable "project_id" { type = string }
variable "region"     { type = string; default = "us-central1" }
variable "zone"       { type = string; default = "us-central1-a" }
variable "environment" {
  type = string
  validation {
    condition = contains(["dev","staging","prod"], var.environment)
    error_message = "Must be dev, staging, or prod."
  }
}
variable "app_name" { type = string }
variable "instance_type" { type = string; default = "e2-micro" }
variable "min_replicas"  { type = number; default = 1 }
variable "max_replicas"  { type = number; default = 3 }
```

```hcl filename="environments/dev/backend.tf"
terraform {
  backend "gcs" {
    bucket = "tf-state-rizeforge-dev"
    prefix = "terraform/state"
  }
}
provider "google" {
  project = var.project_id
  region  = var.region
  zone    = var.zone
}
```

---

## ğŸ§  Automating State Management

To prevent accidental cross-environment overwrites, I created a shell script that provisions **versioned GCS buckets** per environment:

```bash filename="scripts/create-state-buckets.sh"
#!/bin/bash
PROJECT_ID="rizeforge-dev"
for env in dev staging prod; do
  BUCKET="tf-state-rizeforge-$env"
  gsutil mb -p "$PROJECT_ID" -l us-central1 "gs://$BUCKET"
  gsutil versioning set on "gs://$BUCKET"
  gsutil uniformbucketlevelaccess set on "gs://$BUCKET"
done
```

This ensures **state isolation**, **auditable versioning**, and **automatic retention**.

---

## ğŸ§© Terraform Modules

### ğŸ›°ï¸ Networking Module

```hcl
resource "google_compute_network" "main" {
  name                    = "${var.app_name}-${var.environment}-vpc"
  auto_create_subnetworks = false
}
resource "google_compute_subnetwork" "app" {
  name          = "${var.app_name}-${var.environment}-subnet"
  ip_cidr_range = "10.0.0.0/24"
  region        = var.region
  network       = google_compute_network.main.id
}
```

### ğŸ’» Compute Module

```hcl
resource "google_compute_instance_template" "app" {
  name_prefix  = "${var.app_name}-${var.environment}-template-"
  machine_type = var.instance_type
  disk {
    boot         = true
    source_image = "debian-cloud/debian-11"
  }
}
```

### ğŸ“Š Monitoring Module

```hcl
resource "google_monitoring_alert_policy" "high_cpu" {
  display_name = "${var.app_name}-${var.environment} High CPU"
  combiner     = "OR"
  conditions {
    condition_threshold {
      filter          = "metric.type=\"compute.googleapis.com/instance/cpu/utilization\""
      comparison      = "COMPARISON_GT"
      threshold_value = 0.8
      duration        = "300s"
    }
  }
}
```

---

## ğŸ” Security Best Practices

* **Dedicated service accounts** per environment (Terraform, application, monitoring).
* **Least privilege IAM** to reduce the blast radius.
* **Workload Identity Federation** to eliminate static credentials.
* **Versioned GCS backends** for traceability and rollback.

---

## âš™ï¸ CI/CD with Cloud Build

```yaml filename="cloudbuild/cloudbuild-dev.yaml"
steps:
  - name: 'gcr.io/cloud-builders/terraform'
    args: ['init']
    dir: 'environments/dev'
  - name: 'gcr.io/cloud-builders/terraform'
    args: ['plan', '-out=tfplan']
    dir: 'environments/dev'
  - name: 'gcr.io/cloud-builders/terraform'
    args: ['apply', '-auto-approve', 'tfplan']
    dir: 'environments/dev'
substitutions:
  _PROJECT_ID: 'rizeforge-dev'
timeout: 1200s
```

Each environment runs a dedicated pipeline, ensuring reproducible deployments and easier rollback.

---

## ğŸ“Š Results

* âš¡ **100% automated multi-environment deployments** (dev â†’ staging â†’ prod).
* ğŸ”’ **Isolated state management** prevents conflicts and drift.
* ğŸ“ˆ **Reusable Terraform modules** speed up onboarding for new infrastructure.
* ğŸŒ **Integrated monitoring** ensures proactive alerting and observability.

---

## ğŸš€ Lessons Learned

* Enforcing environment isolation early simplifies future scaling.
* Modular design allows infrastructure reuse across multiple projects.
* CI/CD validation (plan â†’ approval â†’ apply) reduces human error.
* GCS state versioning is invaluable for debugging and rollbacks.
